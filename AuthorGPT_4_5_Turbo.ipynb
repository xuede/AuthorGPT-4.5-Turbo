{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuede/AuthorGPT-4.5-Turbo/blob/main/AuthorGPT_4_5_Turbo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih8GSkb28daX"
      },
      "source": [
        "# AuthorGPT-4.5-Turbo\n",
        "\n",
        "Github repo: https://github.com/xuede/AuthorGPT-4_5-Turbo\n",
        "\n",
        "This was only made possible by earlier work by [mshumer/gpt-author](https://github.com/mshumer/gpt-author).\n",
        "\n",
        "I don't have an Anthropic API key, but with GPT-4.5-Turbo's 128k token context window, I wanted to generate the entire book with GPT-4.5-Turbo.\n",
        "\n",
        "\n",
        "Generate an entire novel in minutes, and automatically package it as an e-book.\n",
        "\n",
        "To generate a book:\n",
        "*   ***Set the secrets for your STABILITY_API_KEY and OPENAI_API_KEY in Colab*** by clicking the key icon on the left. The names are as they appear above in caps. The value is the actually API key.\n",
        "*   Make sure the toggle switch is to the right and blue (not grayed out).\n",
        "\n",
        "\n",
        "\n",
        "1.  If you want your ebook saved to Google Drive, run the first cell. If you don't want to save it to the cloud, don't run it and you will be provided a download link at the end.\n",
        "2.  Fill in the prompt, number of chapters, and writing style in the last cell.\n",
        "3.  Run the rest of the cells! When complete you'll have a download link and if you chose to, a copy in your Google Drive at /AI/AuthorGPT/{title}_YYYY_MM_DD.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msO6KzdS41tk"
      },
      "source": [
        "#Optionally save to Google Drive\n",
        "\n",
        "If you want to save your story to your google drive click here and then run all cells. It will save the file to in /content/drive/mydrive/AI/AuthorGPT/{title}_YYMMDD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPoXBoiPuC_H",
        "outputId": "43611ab9-abb8-4ff7-ec48-992115940322",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter Novel Details { run: \"auto\", vertical-output: true }\n",
        "num_chapters = 10 #@param {type:\"integer\"}\n",
        "user_input_prompt = \"Imagine a children's book where all the characters are boogers.\" #@param {type:\"string\"}\n",
        "writing_style = 'Written for a 4th grade reading level, make it humorous, tongue-in-cheek, accessible and page-turning/captivating. It is both silly and smart.' #@param {type:\"string\"}\n",
        "\n",
        "static_text = \"\"\"\n",
        " Welcome to a new session. In this instance, your attention is needed on the mindful use of specific words and phrases that have been identified as frequently used in previous interactions. These include 'delve', 'tapestry', 'weave', 'chronicle', 'veil', 'shadows', 'whisper', 'luminous', 'ethereal', 'verdant', 'resplendent', 'meander', 'soar', 'plunge', 'cascade', 'twilight', 'horizon', 'echo', 'silhouette', 'poignant', 'melancholic', 'exuberant', 'serene', 'existential', 'transcendent', 'ephemeral', 'enigma', 'luminescent', 'iridescent' along with 'silent', 'unseen', 'light'. While these words are not banned, they should be used with discernment and only when they significantly enhance the communication. Guidelines for language use are as follows: Keyword Awareness: Actively recognize these specified words and phrases at the start of each interaction, considering them as terms to be used sparingly. Alternative Vocabulary: Develop and use a list of alternative words and phrases that can effectively convey similar meanings or functions as the flagged words. This alternative list should be a go-to resource in your language composition. Contextual Judgment: Carefully evaluate the necessity of using these words in each context. Opt for alternatives unless these words are crucial for conveying a specific and unique meaning. Diverse Language Styles: Strive to employ a broad array of linguistic styles and tones. This strategy helps in avoiding the overuse of any particular group of words or phrases, ensuring a rich and varied language texture. Reflection and Adaptation: Post-composition, review your responses to check the frequency and appropriateness of the flagged words. Adjust the content to achieve a balanced and diverse language usage. Continual Learning: Each new conversation is an opportunity to refine your language use based on feedback and the specific context, despite the stateless nature of the interactions. This approach is designed to foster a more varied and nuanced use of language, ensuring that your communication remains effective and engaging while avoiding over-reliance on certain words and phrases.\n",
        "\"\"\"\n",
        "# Combine user input with the static text\n",
        "prompt = user_input_prompt + \"\\n\\n\" + static_text\n",
        "\n",
        "# Now, 'prompt' contains both the user input and the static text\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Yp8Cr8dZ_zh7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR51yZrgFJAY"
      },
      "source": [
        "## Install Dependancies and Functions Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Dependancies"
      ],
      "metadata": {
        "id": "kYjvw8jpk9A0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPjGp5JCFGhO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "!pip install cohere\n",
        "!pip install tiktoken\n",
        "!pip install openai\n",
        "!pip install EbookLib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and set OpenAI and Stability keys from Secrets"
      ],
      "metadata": {
        "id": "Fbl8g_1QiFh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HTGF4Bw6Hnuz",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import openai\n",
        "import os\n",
        "from ebooklib import epub\n",
        "import base64\n",
        "import os\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "# Retrieve the OpenAI API key\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Set the API key for OpenAI\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Similarly, if you need to retrieve another key, for example, for Stability AI\n",
        "STABILITY_API_KEY = userdata.get('STABILITY_API_KEY')\n",
        "\n",
        "#openai.api_key = \"OPENAI_API_KEY\" # get it at https://platform.openai.com/\n",
        "#stability_api_key = \"STABILITY_API_KEY\" # get it at https://beta.dreamstudio.ai/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Novel Writing Functions Setup: AI-Assisted Plot Generation and Chapter Development"
      ],
      "metadata": {
        "id": "YI_Mpo-KixsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KEClRDpDK7VW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import openai\n",
        "import random\n",
        "import json\n",
        "import ast\n",
        "\n",
        "def print_step_costs(response, model):\n",
        "    input_tokens = response.usage.prompt_tokens\n",
        "    output_tokens = response.usage.completion_tokens\n",
        "\n",
        "    # Set default values\n",
        "    input_per_token = 0\n",
        "    output_per_token = 0\n",
        "\n",
        "    if model == \"gpt-4\":\n",
        "        input_per_token = 0.03 / 1000\n",
        "        output_per_token = 0.06 / 1000\n",
        "    elif model == \"gpt-4-1106-preview\":\n",
        "        input_per_token = 0.01 / 1000\n",
        "        output_per_token = 0.03 / 1000\n",
        "\n",
        "    input_cost = input_tokens * input_per_token\n",
        "    output_cost = output_tokens * output_per_token\n",
        "\n",
        "    total_cost = input_cost + output_cost\n",
        "    print('Step Cost (OpenAI):', total_cost)\n",
        "\n",
        "\n",
        "def generate_plots(prompt):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative assistant that generates engaging surreal novel plots.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Generate 10 surreal novel plots based on this prompt: {prompt}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    return response.choices[0].message.content.split('\\n')\n",
        "\n",
        "def select_most_engaging(plots):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in writing fantastic surrealist novel plots.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here are a number of possible plots for a new novel: {plots}\\n\\n--\\n\\nNow, write the final plot that we will go with. It can be one of these, a mix of the best elements of multiple, or something completely new and better. The most important thing is the plot should be fantastic, unique, and engaging.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def improve_plot(plot):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in improving and refining story plots.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Improve this plot: {plot}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "def get_title(improved_plot):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert writer.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here is the plot: {improved_plot}\\n\\nWhat is the title of this book? Just respond with the title, do nothing else.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def write_first_chapter(plot, first_chapter_title, writing_style):\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "          model=\"gpt-4-1106-preview\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": \"You are a world-class surrealist writer.\"},\n",
        "              {\"role\": \"user\", \"content\": f\"Here is the high-level plot to follow: {plot}\\n\\nWrite the first chapter of this novel: `{first_chapter_title}`.\\n\\nMake it incredibly unique, engaging, and well-written.\\n\\nHere is a description of the writing style you should use: `{writing_style}`\\n\\nInclude only the chapter text. There is no need to rewrite the chapter name.\"}\n",
        "          ]\n",
        "      )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    improved_response = openai.chat.completions.create(\n",
        "          model=\"gpt-4-1106-preview\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": \"You are a world-class surrealist writer. Your job is to take your student's rough initial draft of the first chapter of their surrealist novel, and rewrite it to be significantly better, with much more detail.\"},\n",
        "              {\"role\": \"user\", \"content\": f\"Here is the high-level plot you asked your student to follow: {plot}\\n\\nHere is the first chapter they wrote: {response.choices[0].message.content}\\n\\nNow, rewrite the first chapter of this novel, in a way that is far superior to your student's chapter. It should still follow the exact same plot, but it should be far more detailed, much longer, and more engaging. Here is a description of the writing style you should use: `{writing_style}`\"}\n",
        "          ]\n",
        "      )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    return improved_response.choices[0].message.content\n",
        "\n",
        "\n",
        "def write_chapter(previous_chapters, plot, chapter_title):\n",
        "        try:\n",
        "            i = random.randint(1,2242)\n",
        "            response = openai.chat.completions.create(\n",
        "                model=\"gpt-4-1106-preview\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a world-class surrealist writer.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Plot: {plot}, Previous Chapters: {previous_chapters}\\n\\n--\\n\\nWrite the next chapter of this novel, following the plot and taking in the previous chapters as context. Here is the plan for this chapter: {chapter_title}\\n\\nWrite it beautifully. Include only the chapter text. There is no need to rewrite the chapter name.\"}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        except:\n",
        "            response = openai.chat.completions.create(\n",
        "                model=\"gpt-4-1106-preview\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a world-class surrealist writer.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Plot: {plot}, Previous Chapters: {previous_chapters}\\n\\n--\\n\\nWrite the next chapter of this novel, following the plot and taking in the previous chapters as context. Here is the plan for this chapter: {chapter_title}\\n\\nWrite it beautifully. Include only the chapter text. There is no need to rewrite the chapter name.\"}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "def generate_storyline(prompt, num_chapters):\n",
        "    print(\"Generating storyline with chapters and high-level details...\")\n",
        "    json_format = \"\"\"[{\"Chapter CHAPTER_NUMBER_HERE - CHAPTER_TITLE_GOES_HERE\": \"CHAPTER_OVERVIEW_AND_DETAILS_GOES_HERE\"}, ...]\"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a world-class surrealist writer. Your job is to write a detailed storyline, complete with chapters, for a fantasy novel. Don't be flowery -- you want to get the message across in as few words as possible. But those words should contain lots of information.\"},\n",
        "            {\"role\": \"user\", \"content\": f'Write a fantastic storyline with {num_chapters} chapters and high-level details based on this plot: {prompt}.\\n\\nDo it in this list of dictionaries format {json_format}'}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    improved_response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a world-class surrealist writer. Your job is to take your student's rough initial draft of the storyline of a fantasy novel, and rewrite it to be significantly better.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here is the draft storyline they wrote: {response.choices[0].message.content}\\n\\nNow, rewrite the storyline, in a way that is far superior to your student's version. It should have the same number of chapters, but it should be much improved in as many ways as possible. Remember to do it in this list of dictionaries format {json_format}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(improved_response, \"gpt-4-1106-preview\")\n",
        "\n",
        "    return improved_response.choices[0].message.content\n",
        "\n",
        "def write_to_file(prompt, content):\n",
        "\n",
        "    # Create a directory for the prompts if it doesn't exist\n",
        "    if not os.path.exists('prompts'):\n",
        "        os.mkdir('prompts')\n",
        "\n",
        "    # Replace invalid characters for filenames\n",
        "    valid_filename = ''.join(c for c in prompt if c.isalnum() or c in (' ', '.', '_')).rstrip()\n",
        "    file_path = f'prompts/{valid_filename}.txt'\n",
        "\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    print(f'Output for prompt \"{prompt}\" has been written to {file_path}\\n')\n",
        "\n",
        "\n",
        "def write_novel(prompt, num_chapters, writing_style):\n",
        "    plots = generate_plots(prompt)\n",
        "    print('generated plots')\n",
        "\n",
        "    best_plot = select_most_engaging(plots)\n",
        "    print('selected best plot')\n",
        "\n",
        "    improved_plot = improve_plot(best_plot)\n",
        "    print('plot improved')\n",
        "\n",
        "    title = get_title(improved_plot)\n",
        "    print('title generated')\n",
        "\n",
        "    storyline = generate_storyline(improved_plot, num_chapters)\n",
        "    print('storyline generated')\n",
        "    chapter_titles = ast.literal_eval(storyline)\n",
        "\n",
        "\n",
        "    novel = f\"Storyline:\\n{storyline}\\n\\n\"\n",
        "\n",
        "    first_chapter = write_first_chapter(storyline, chapter_titles[0], writing_style.strip())\n",
        "    print('first chapter written')\n",
        "    novel += f\"Chapter 1:\\n{first_chapter}\\n\"\n",
        "    chapters = [first_chapter]\n",
        "\n",
        "    for i in range(num_chapters - 1):\n",
        "        print(f\"Writing chapter {i+2}...\")  # + 2 because the first chapter was already added\n",
        "\n",
        "        chapter = write_chapter(novel, storyline, chapter_titles[i+1])\n",
        "        try:\n",
        "            if len(str(chapter)) < 100:\n",
        "                print('Length minimum not hit. Trying again.')\n",
        "                chapter = write_chapter(novel, storyline, chapter_titles[i+1])\n",
        "        except:\n",
        "            chapter = write_chapter(novel, storyline, chapter_titles[i+1])\n",
        "\n",
        "        novel += f\"Chapter {i+2}:\\n{chapter}\\n\"\n",
        "        chapters.append(chapter)\n",
        "\n",
        "    with open('output.txt', 'w') as file:\n",
        "        # Write data to the file\n",
        "        file.write(f\"Title: {title}\\n\")\n",
        "        file.write(\"Chapters:\\n\")\n",
        "        for chapter_title, chapter_content in zip(chapter_titles, chapters):\n",
        "            file.write(f\"Chapter: {chapter_title}\\n\")\n",
        "            file.write(chapter_content)\n",
        "            file.write('\\n')\n",
        "\n",
        "    return novel, title, chapters, chapter_titles\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Epub Generation Functions Setup: Formatting, and Generation"
      ],
      "metadata": {
        "id": "V3A9b39yi5D6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4w-tRWAVDf-V",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def create_epub(title, author, chapters, cover_image_path='cover.png'):\n",
        "    book = epub.EpubBook()\n",
        "\n",
        "    # Set metadata\n",
        "    book.set_identifier('id8797656')\n",
        "    book.set_title(title)\n",
        "    book.set_language('en')\n",
        "    book.add_author(author)\n",
        "\n",
        "    # Add cover image\n",
        "    with open(cover_image_path, 'rb') as cover_file:\n",
        "        cover_image = cover_file.read()\n",
        "    book.set_cover('cover.png', cover_image)\n",
        "\n",
        "    # Create chapters and add them to the book\n",
        "    epub_chapters = []\n",
        "    for i, chapter_dict in enumerate(chapters):\n",
        "        full_chapter_title = list(chapter_dict.keys())[0]\n",
        "        chapter_content = list(chapter_dict.values())[0]\n",
        "        if ' - ' in full_chapter_title:\n",
        "            chapter_title = full_chapter_title.split(' - ')[1]\n",
        "        else:\n",
        "            chapter_title = full_chapter_title\n",
        "\n",
        "        chapter_file_name = f'chapter_{i+1}.xhtml'\n",
        "        epub_chapter = epub.EpubHtml(title=chapter_title, file_name=chapter_file_name, lang='en')\n",
        "\n",
        "        # Add paragraph breaks\n",
        "        formatted_content = ''.join(f'<p>{paragraph.strip()}</p>' for paragraph in chapter_content.split('\\n') if paragraph.strip())\n",
        "\n",
        "        epub_chapter.content = f'<h1>{chapter_title}</h1>{formatted_content}'\n",
        "        book.add_item(epub_chapter)\n",
        "        epub_chapters.append(epub_chapter)\n",
        "\n",
        "\n",
        "    # Define Table of Contents\n",
        "    book.toc = (epub_chapters)\n",
        "\n",
        "    # Add default NCX and Nav files\n",
        "    book.add_item(epub.EpubNcx())\n",
        "    book.add_item(epub.EpubNav())\n",
        "\n",
        "    # Define CSS style\n",
        "    style = '''\n",
        "    @namespace epub \"http://www.idpf.org/2007/ops\";\n",
        "    body {\n",
        "        font-family: Cambria, Liberation Serif, serif;\n",
        "    }\n",
        "    h1 {\n",
        "        text-align: left;\n",
        "        text-transform: uppercase;\n",
        "        font-weight: 200;\n",
        "    }\n",
        "    '''\n",
        "\n",
        "    # Add CSS file\n",
        "    nav_css = epub.EpubItem(uid=\"style_nav\", file_name=\"style/nav.css\", media_type=\"text/css\", content=style)\n",
        "    book.add_item(nav_css)\n",
        "\n",
        "    # Create spine\n",
        "    book.spine = ['nav'] + epub_chapters\n",
        "\n",
        "    # Save the EPUB file\n",
        "    epub.write_epub(f'{title}.epub', book)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cover Generation Functions Setup"
      ],
      "metadata": {
        "id": "wIjvegjTjfGq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "__nvOnmhPqwy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def generate_cover_prompt(plot):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4-1106-preview\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative assistant that writes a spec for the cover art of a book, based on the book's plot.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Plot: {plot}\\n\\n--\\n\\nDescribe the cover we should create, based on the plot. This should be two sentences long, maximum.\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def create_cover_image(plot):\n",
        "\n",
        "  plot = str(generate_cover_prompt(plot))\n",
        "\n",
        "# Retrieve the Stability AI API key\n",
        "  STABILITY_API_KEY = userdata.get('STABILITY_API_KEY')\n",
        "\n",
        "  engine_id = \"stable-diffusion-xl-beta-v2-2-2\"\n",
        "  api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
        "  api_key = STABILITY_API_KEY  # Use the retrieved secret key\n",
        "\n",
        "  if api_key is None:\n",
        "      raise Exception(\"Missing Stability API key.\")\n",
        "\n",
        "  response = requests.post(\n",
        "      f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
        "      headers={\n",
        "          \"Content-Type\": \"application/json\",\n",
        "          \"Accept\": \"application/json\",\n",
        "          \"Authorization\": f\"Bearer {api_key}\"\n",
        "      },\n",
        "      json={\n",
        "          \"text_prompts\": [\n",
        "              {\n",
        "                  \"text\": plot\n",
        "              }\n",
        "          ],\n",
        "          \"cfg_scale\": 7,\n",
        "          \"clip_guidance_preset\": \"FAST_BLUE\",\n",
        "          \"height\": 768,\n",
        "          \"width\": 512,\n",
        "          \"samples\": 1,\n",
        "          \"steps\": 30,\n",
        "      },\n",
        "  )\n",
        "\n",
        "  if response.status_code != 200:\n",
        "      raise Exception(\"Non-200 response: \" + str(response.text))\n",
        "\n",
        "  data = response.json()\n",
        "\n",
        "  for i, image in enumerate(data[\"artifacts\"]):\n",
        "      with open(f\"/content/cover.png\", \"wb\") as f: # replace this if running locally, to where you store the cover file\n",
        "          f.write(base64.b64decode(image[\"base64\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diBD0hfuvsEo"
      },
      "source": [
        "\n",
        "# **Generate the Novel!**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Novel Content"
      ],
      "metadata": {
        "id": "mRBAjQR2lWpV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0s5g8WaIrYDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "b2bc2da5-e118-49ce-e016-5e322d0c5639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step Cost (OpenAI): 0.024669999999999997\n",
            "generated plots\n",
            "Step Cost (OpenAI): 0.030889999999999997\n",
            "selected best plot\n",
            "Step Cost (OpenAI): 0.02787\n",
            "plot improved\n",
            "Step Cost (OpenAI): 0.007450000000000001\n",
            "title generated\n",
            "Generating storyline with chapters and high-level details...\n",
            "Step Cost (OpenAI): 0.026569999999999996\n",
            "Step Cost (OpenAI): 0.03325\n",
            "storyline generated\n",
            "Step Cost (OpenAI): 0.02874\n",
            "Step Cost (OpenAI): 0.02874\n",
            "first chapter written\n",
            "Writing chapter 2...\n",
            "Step Cost (OpenAI): 0.04974\n",
            "Writing chapter 3...\n",
            "Step Cost (OpenAI): 0.06094000000000001\n",
            "Writing chapter 4...\n",
            "Step Cost (OpenAI): 0.0717\n",
            "Writing chapter 5...\n",
            "Step Cost (OpenAI): 0.07961\n",
            "Writing chapter 6...\n",
            "Step Cost (OpenAI): 0.0897\n",
            "Writing chapter 7...\n",
            "Step Cost (OpenAI): 0.09735\n",
            "Writing chapter 8...\n",
            "Step Cost (OpenAI): 0.10604000000000001\n",
            "Writing chapter 9...\n",
            "Step Cost (OpenAI): 0.11522\n",
            "Writing chapter 10...\n",
            "Step Cost (OpenAI): 0.12349\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "novel, title, chapters, chapter_titles = write_novel(prompt, num_chapters, writing_style)\n",
        "\n",
        "# Replace chapter descriptions with body text in chapter_titles\n",
        "for i, chapter in enumerate(chapters):\n",
        "    chapter_number_and_title = list(chapter_titles[i].keys())[0]\n",
        "    chapter_titles[i] = {chapter_number_and_title: chapter}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Cover and Create ePub"
      ],
      "metadata": {
        "id": "60eWFSWHlPeT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WMbXL2rxqeaB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "create_cover_image(str(chapter_titles))\n",
        "\n",
        "# Create the EPUB file\n",
        "create_epub(title, 'AuthorGPT', chapter_titles, '/content/cover.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqLGSOsYrj8k"
      },
      "source": [
        "### Copy to your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ThRw7tl2sXv3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "cellView": "form",
        "outputId": "a756deda-ee5a-465b-a9e7-e72a6634d3b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All non-directory files from /content/ copied to /content/drive/MyDrive/AI/AuthorGPT/Nasal Nexus: The Last Booger_2023_11_21\n",
            "Click below to download the eBook.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41e6f316-b77d-4377-a147-11518e864a28\", \"cover.png\", 734851)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_61419b47-ca91-4a9e-831a-8b56d1d16413\", \"Nasal Nexus: The Last Booger.epub\", 750989)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1adf5fdb-4fb8-42d6-8147-cf004fbf56dc\", \"output.txt\", 42967)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title\n",
        "import os\n",
        "import shutil\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "# Function to download files from a directory\n",
        "def download_files_from_directory(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            files.download(file_path)\n",
        "\n",
        "# Directories\n",
        "source_directory = '/content/'\n",
        "drive_mount_point = '/content/drive/'\n",
        "base_destination_directory = os.path.join(drive_mount_point, 'MyDrive/AI/AuthorGPT/')\n",
        "\n",
        "# Check if the destination directory exists on Google Drive\n",
        "if not os.path.exists(base_destination_directory):\n",
        "    base_destination_directory = '/content/'\n",
        "\n",
        "# Make assignment statement\n",
        "ebook_title = title\n",
        "\n",
        "# Create a timestamped directory with the eBook title\n",
        "current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
        "destination_directory = os.path.join(base_destination_directory, f\"{ebook_title}_{current_date}\")\n",
        "os.makedirs(destination_directory, exist_ok=True)\n",
        "\n",
        "# Copy all non-directory files\n",
        "for filename in os.listdir(source_directory):\n",
        "    source_file = os.path.join(source_directory, filename)\n",
        "    destination_file = os.path.join(destination_directory, filename)\n",
        "    if os.path.isfile(source_file):\n",
        "        shutil.copy2(source_file, destination_file)\n",
        "\n",
        "# Confirmation messages\n",
        "print(f'All non-directory files from {source_directory} copied to {destination_directory}')\n",
        "print('Click below to download the eBook.')\n",
        "\n",
        "# Generate download link(s) for the files\n",
        "download_files_from_directory(destination_directory)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
